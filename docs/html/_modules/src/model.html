<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>src.model &mdash; GeneFlow 0.8 documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html"><img src="../../_static/geneflow_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">GeneFlow:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../geneflow.html">GeneFlow</a></li>
</ul>
<p class="caption"><span class="caption-text">Modules:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../src.html">DataObject</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src.html#module-src.etl">ETL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src.html#module-src.model">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src.html#module-src.objects">Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src.html#module-src.processing">Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src.html#module-src.utils">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src.html#module-src.visualize">Visualize</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">GeneFlow</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>src.model</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for src.model</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">@author: Alba Casillas Rodr√≠guez (albacaro@correo.ugr.es)</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">src</span> <span class="kn">import</span> <span class="n">utils</span> <span class="k">as</span> <span class="n">ut</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Import Packages and import functions for modeling</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span> <span class="k">as</span> <span class="n">skLogisticRegression</span>
<span class="c1"># from sklearn.naive_bayes import GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span> <span class="k">as</span> <span class="n">skRandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span> <span class="k">as</span> <span class="n">skMLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_validate</span><span class="p">,</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span><span class="n">roc_curve</span><span class="p">,</span> <span class="n">precision_recall_curve</span><span class="p">,</span> <span class="n">auc</span>

<span class="kn">from</span> <span class="nn">imblearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>
<span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">RandomUnderSampler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>


<div class="viewcode-block" id="ModelSelection"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection">[docs]</a><span class="k">class</span> <span class="nc">ModelSelection</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;This class performs different techniques to the data such as: splitting data,</span>
<span class="sd">    over-sampling and under-sampling, normalization, computes confusion matrix and AUC, etc.,</span>
<span class="sd">    to the data in order to improve Machine Learning algorithm&#39;s performance.</span>
<span class="sd">    </span>
<span class="sd">    :param data: The data to apply Machine Learning methods. Defaults to None.</span>
<span class="sd">        If it is not specified, user must provide the &#39;source&#39; and &#39;target&#39; values.</span>
<span class="sd">    :type data: DataFrame</span>
<span class="sd">    :param source: The features that describe the samples. Defaults to None.</span>
<span class="sd">        If it is noy specified, user must provide &#39;data&#39; value. </span>
<span class="sd">        Otherwise, if it is different to None, &#39;target&#39; values must be provided.</span>
<span class="sd">    :type source: DataFrame</span>
<span class="sd">    :param target: The labels to be predicted. Defaults to None.</span>
<span class="sd">        If it is noy specified, user must provide &#39;data&#39; value. </span>
<span class="sd">        Otherwise, if it is different to None, &#39;source&#39; values must be provided.</span>
<span class="sd">    :type target: Series</span>
<span class="sd">    :param X_train: All the observations that will be used to train the model.</span>
<span class="sd">        Defaults to None. Only can be updated after use &#39;get_train_test_sample&#39; method.</span>
<span class="sd">    :type X_train: DataFrame</span>
<span class="sd">    :param Y_train: The dependent variable wich need to be predicted by the model.</span>
<span class="sd">        Defaults to None. Only can be updated after use &#39;get_train_test_sample&#39; method.</span>
<span class="sd">    :type Y_train: Series</span>
<span class="sd">    :param X_test:  The remaining portion of the independent  variables which </span>
<span class="sd">        will not be used in the training phase and will be used</span>
<span class="sd">        to make predictions to test the accuracy of the model.</span>
<span class="sd">        Defaults to None. Only can be updated after use &#39;get_train_test_sample&#39; method.</span>
<span class="sd">    :type X_test: DataFrame</span>
<span class="sd">    :param Y_test: The labels of the test data. These labels will be used to test </span>
<span class="sd">        the accuracy between actual and predicted categories. Defaults to None.</span>
<span class="sd">        Only can be updated after use &#39;get_train_test_sample&#39; method.</span>
<span class="sd">    :type Y_test:  Series</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="sd">&quot;&quot;&quot;Constructor method</span>
<span class="sd">    &quot;&quot;&quot;</span>  
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">source</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>  
        
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">source</span> <span class="o">=</span> <span class="n">source</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y_train</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y_test</span> <span class="o">=</span> <span class="kc">None</span>
        
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    GET</span>
<span class="sd">    &quot;&quot;&quot;</span>
        
<div class="viewcode-block" id="ModelSelection.get_data"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.get_data">[docs]</a>    <span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a DataFrame with the data to apply Machine Learning methods.</span>
<span class="sd">        </span>
<span class="sd">        :return: The data to apply Machine Learning methods.</span>
<span class="sd">        :rtype: DataFrame</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span></div>
    
<div class="viewcode-block" id="ModelSelection.get_source"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.get_source">[docs]</a>    <span class="k">def</span> <span class="nf">get_source</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a DataFrame with the attributes used to describe each example.</span>
<span class="sd">        </span>
<span class="sd">        :return: The features that describe the samples.</span>
<span class="sd">        :rtype: DataFrame</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span></div>
    
<div class="viewcode-block" id="ModelSelection.get_target"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.get_target">[docs]</a>    <span class="k">def</span> <span class="nf">get_target</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a Series object with the labels to be predicted.</span>
<span class="sd">        </span>
<span class="sd">        :return: The labels to be predicted.</span>
<span class="sd">        :rtype: Series</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span></div>
    
<div class="viewcode-block" id="ModelSelection.get_X_train"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.get_X_train">[docs]</a>    <span class="k">def</span> <span class="nf">get_X_train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a DataFrame with all the observations that will be used to</span>
<span class="sd">        train the model.</span>
<span class="sd">        </span>
<span class="sd">        :return: All independent variables used to train the model.</span>
<span class="sd">        :rtype: DataFrame</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span></div>
    
<div class="viewcode-block" id="ModelSelection.get_Y_train"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.get_Y_train">[docs]</a>    <span class="k">def</span> <span class="nf">get_Y_train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a Series object with the dependent variables which need to be</span>
<span class="sd">        predicted by the model.</span>
<span class="sd">        </span>
<span class="sd">        :return: The dependent variable wich need to be predicted by the model.</span>
<span class="sd">        :rtype: Series</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y_train</span></div>
    
<div class="viewcode-block" id="ModelSelection.get_X_test"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.get_X_test">[docs]</a>    <span class="k">def</span> <span class="nf">get_X_test</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a DataFrame with the remaining portion of the independent </span>
<span class="sd">        variables which will not be used in the training phase and will be used</span>
<span class="sd">        to make predictions to test the accuracy of the model.</span>
<span class="sd">        </span>
<span class="sd">        :return: Remaining observations to test the accuracy of the model.</span>
<span class="sd">        :rtype: DataFrame</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span></div>
    
<div class="viewcode-block" id="ModelSelection.get_Y_test"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.get_Y_test">[docs]</a>    <span class="k">def</span> <span class="nf">get_Y_test</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a Series object with the labels of the test data. These labels</span>
<span class="sd">        will be used to test the accuracy between actual and predicted categories.</span>
<span class="sd">        </span>
<span class="sd">        :return: The labels to test the accuracy of the model.</span>
<span class="sd">        :rtype: Series</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y_test</span></div>
    

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    SET</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
<div class="viewcode-block" id="ModelSelection.set_data"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.set_data">[docs]</a>    <span class="k">def</span> <span class="nf">set_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the data to apply Machine Learning methods.</span>
<span class="sd">        </span>
<span class="sd">        :param data: The data to apply Machine Learning methods.</span>
<span class="sd">        :type data: DataFrame </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span></div>
        
<div class="viewcode-block" id="ModelSelection.set_source"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.set_source">[docs]</a>    <span class="k">def</span> <span class="nf">set_source</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the features that describe the samples.</span>
<span class="sd">        </span>
<span class="sd">        :param source:  The features that describe the samples.</span>
<span class="sd">        :type source: DatFrame </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source</span> <span class="o">=</span> <span class="n">source</span></div>
        
<div class="viewcode-block" id="ModelSelection.set_target"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.set_target">[docs]</a>    <span class="k">def</span> <span class="nf">set_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the labels to be predicted.</span>
<span class="sd">        </span>
<span class="sd">        :param target: The labels to be predicted.</span>
<span class="sd">        :type target: Series </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span></div>
        
<div class="viewcode-block" id="ModelSelection.set_X_train"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.set_X_train">[docs]</a>    <span class="k">def</span> <span class="nf">set_X_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_train</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the independent variables used to train the model.</span>
<span class="sd">        </span>
<span class="sd">        :param x_train: All independent variables used to train the model.</span>
<span class="sd">        :type x_train: DataFrame </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">x_train</span></div>
        
<div class="viewcode-block" id="ModelSelection.set_Y_train"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.set_Y_train">[docs]</a>    <span class="k">def</span> <span class="nf">set_Y_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the dependent variable wich need to be predicted by the model.</span>
<span class="sd">        </span>
<span class="sd">        :param y_train: The dependent variables wich need to be predicted by the model.</span>
<span class="sd">        :type y_train: Series </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">y_train</span></div>
        
<div class="viewcode-block" id="ModelSelection.set_X_test"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.set_X_test">[docs]</a>    <span class="k">def</span> <span class="nf">set_X_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_test</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the remaining observations to test the accuracy of the model.</span>
<span class="sd">        </span>
<span class="sd">        :param x_test: Remaining observations to test the accuracy of the model.</span>
<span class="sd">        :type x_test: DataFrame </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span> <span class="o">=</span> <span class="n">x_test</span></div>
        
<div class="viewcode-block" id="ModelSelection.set_Y_test"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.set_Y_test">[docs]</a>    <span class="k">def</span> <span class="nf">set_Y_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the labels to test the accuracy of the model.</span>
<span class="sd">        </span>
<span class="sd">        :param y_test: The labels to test the accuracy of the model.</span>
<span class="sd">        :type y_test: str </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y_test</span> <span class="o">=</span> <span class="n">y_test</span></div>


<div class="viewcode-block" id="ModelSelection.split_data"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.split_data">[docs]</a>    <span class="k">def</span> <span class="nf">split_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>   
        <span class="sd">&quot;&quot;&quot;Split input data into sources (samples) and target (labels).</span>
<span class="sd">        Target data will be the last column of the data.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>   
        
        <span class="bp">self</span><span class="o">.</span><span class="n">set_source</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_target</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>     </div>
    

<div class="viewcode-block" id="ModelSelection.get_train_test_sample"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.get_train_test_sample">[docs]</a>    <span class="k">def</span> <span class="nf">get_train_test_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">resample</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Split the data into random train and test subsets.</span>
<span class="sd">        If &#39;resample&#39; is &#39;True&#39;, Smote and Underasmpler techniques will be also applied</span>
<span class="sd">        to resample imbalanced data.</span>
<span class="sd">        </span>
<span class="sd">        :param test_size: If float, should be between 0.0 and 1.0 and represent </span>
<span class="sd">            the proportion of the dataset to include in the test split. </span>
<span class="sd">            If int, represents the absolute number of test samples. </span>
<span class="sd">            If None, the value is set to the complement of the train size. </span>
<span class="sd">            Defaults to &#39;0.2&#39;.</span>
<span class="sd">        :type test_size: float, int or None</span>
<span class="sd">        :param resample: If &#39;True&#39;, data will be resampled, &#39;False&#39; will not modify </span>
<span class="sd">            the data. Defaults to &#39;False&#39;.</span>
<span class="sd">        :type resample: bool</span>
<span class="sd">        :param shuffle: Whether or not to shuffle the data before splitting.</span>
<span class="sd">            Dafaults to &#39;True&#39;.</span>
<span class="sd">        :type shuffle: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="k">if</span> <span class="n">resample</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">over_under_sample</span><span class="p">(</span><span class="n">o_samp_str</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">u_samp_str</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">)</span>
                                                                                                                                                                                                                                                                                                                                                                                       
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_source</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target</span><span class="p">(),</span> <span class="n">test_size</span> <span class="o">=</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_train</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_test</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_Y_train</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_Y_test</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span></div>



<div class="viewcode-block" id="ModelSelection.apply_smote"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.apply_smote">[docs]</a>    <span class="k">def</span> <span class="nf">apply_smote</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sampling_strategy</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">k_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Applies SMOTE (Synthetic Minority Over-sampling Technique) to perform</span>
<span class="sd">        over-sampling.</span>
<span class="sd">        </span>
<span class="sd">        For more information, see imbalanced learn documentation:</span>
<span class="sd">        https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html</span>
<span class="sd">        </span>
<span class="sd">        :param sampling_strategy: Sampling information to resample the data set.</span>
<span class="sd">            Defaults to &#39;auto&#39;.</span>
<span class="sd">        :type sampling_strategy: float, str, dict or callable</span>
<span class="sd">        :param random_state: Control the randomization of the algorithm. Defaults to None.</span>
<span class="sd">        :type random_state: int, RandomState instance or None</span>
<span class="sd">        :param k_neighbors: Number of neighbours to used to construct synthethic samples.</span>
<span class="sd">            Defaults to &#39;5&#39;.</span>
<span class="sd">        :type k_neighbors: int or Object</span>
<span class="sd">        :param n_jobs: Number of CPU cores used during the cross-validation loop. Defaults to None.</span>
<span class="sd">        :type n_jobs: int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">over</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">sampling_strategy</span> <span class="o">=</span> <span class="n">sampling_strategy</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">k_neighbors</span> <span class="o">=</span> <span class="n">k_neighbors</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span><span class="p">)</span>
        
        <span class="n">X_res</span><span class="p">,</span> <span class="n">Y_res</span> <span class="o">=</span> <span class="n">over</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_source</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_source</span><span class="p">(</span><span class="n">X_res</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_target</span><span class="p">(</span><span class="n">Y_res</span><span class="p">)</span>  </div>



<div class="viewcode-block" id="ModelSelection.apply_undersampler"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.apply_undersampler">[docs]</a>    <span class="k">def</span> <span class="nf">apply_undersampler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sampling_strategy</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">replacement</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Applies RandomUnderSampler  to perform random under-sampling.</span>
<span class="sd">        The method under-sample the majority class(es) by randomly picking samples </span>
<span class="sd">        with or without replacement.</span>
<span class="sd">        </span>
<span class="sd">        For more information, see imbalanced learn documentation:</span>
<span class="sd">        https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html</span>
<span class="sd">        </span>
<span class="sd">        :param sampling_strategy: Sampling information to resample the data set.</span>
<span class="sd">            Defaults to &#39;auto&#39;.</span>
<span class="sd">        :type sampling_strategy: float, str, dict or callable</span>
<span class="sd">        :param random_state: Control the randomization of the algorithm. Defaults to None.</span>
<span class="sd">        :type random_state: int, RandomState instance or None</span>
<span class="sd">        :param replacement: Whether the sample is with or without replacement. Defaults to False.</span>
<span class="sd">        :type replacement: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">under</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">sampling_strategy</span> <span class="o">=</span> <span class="n">sampling_strategy</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">replacement</span> <span class="o">=</span> <span class="n">replacement</span><span class="p">)</span>

        <span class="n">X_res</span><span class="p">,</span> <span class="n">Y_res</span> <span class="o">=</span> <span class="n">under</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_source</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_source</span><span class="p">(</span><span class="n">X_res</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_target</span><span class="p">(</span><span class="n">Y_res</span><span class="p">)</span> </div>
    
    
<div class="viewcode-block" id="ModelSelection.over_under_sample"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.over_under_sample">[docs]</a>    <span class="k">def</span> <span class="nf">over_under_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">o_samp_str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">u_samp_str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">o_random_st</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">u_random_st</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Combines over and under sample to avoid over-fitting or missing too much information.</span>
<span class="sd">        Both techniques will be combines by using Pipeline from imblearn, that provides a pipeline</span>
<span class="sd">        by applying a list of transformations, and resamples, with a final estimator.</span>
<span class="sd">        </span>
<span class="sd">        :param o_samp_str: For SMOTE, sampling information to resample the data set.</span>
<span class="sd">            Defaults to &#39;auto&#39;.</span>
<span class="sd">        :type o_samp_str: float, str, dict or callable</span>
<span class="sd">        :param u_samp_str: For UnderSampler, sampling information to resample the data set.</span>
<span class="sd">            Defaults to &#39;auto&#39;.</span>
<span class="sd">        :type u_samp_str: float, str, dict or callable</span>
<span class="sd">        :param o_random_st: For SMOTE, control the randomization of the algorithm. </span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type o_random_st: int, RandomState instance or None</span>
<span class="sd">        :param u_random_st: For UnderSampler, control the randomization of the algorithm. </span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type u_random_st: int, RandomState instance or None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">over</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">sampling_strategy</span> <span class="o">=</span> <span class="n">o_samp_str</span><span class="p">)</span>
        
        <span class="n">under</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">sampling_strategy</span> <span class="o">=</span> <span class="n">u_samp_str</span><span class="p">)</span>
        
        <span class="n">steps</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">over</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;u&#39;</span><span class="p">,</span> <span class="n">under</span><span class="p">)]</span>
        <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
        
        <span class="n">X_res</span><span class="p">,</span> <span class="n">Y_res</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_source</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target</span><span class="p">())</span> 
        
        <span class="bp">self</span><span class="o">.</span><span class="n">set_source</span><span class="p">(</span><span class="n">X_res</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_target</span><span class="p">(</span><span class="n">Y_res</span><span class="p">)</span> </div>



<div class="viewcode-block" id="ModelSelection.standarize"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.standarize">[docs]</a>    <span class="k">def</span> <span class="nf">standarize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Normalize the data standarizing features by removing the man ands scaling to unit variance.</span>
<span class="sd">        With it, the mean will be 0 and the standard deviation will be 1, following the equation:</span>
<span class="sd">        X_stand = (x - mean(x)) / standard deviation(x)</span>
<span class="sd">        </span>
<span class="sd">        For more information, see:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html     </span>
<span class="sd">        &quot;&quot;&quot;</span>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        
        <span class="c1"># Fit only to the training data</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_X_train</span><span class="p">())</span>
        
        <span class="c1"># Now apply the transformations to the data:</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_X_train</span><span class="p">())</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_X_test</span><span class="p">())</span>     
           
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_train</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_test</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></div>
    
 
<div class="viewcode-block" id="ModelSelection.get_predictions"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.get_predictions">[docs]</a>    <span class="k">def</span> <span class="nf">get_predictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>    
        <span class="sd">&quot;&quot;&quot;Get prediction values.</span>
<span class="sd">        </span>
<span class="sd">        :param probabilities: list of probabilities of the X data that represent a percentage of its result</span>
<span class="sd">        :type probabilities: list </span>
<span class="sd">        :param threshold: a limit to indicates when the classification will be 0 or 1</span>
<span class="sd">        :type threshold: float</span>

<span class="sd">        :return: a predicted values by probabilities</span>
<span class="sd">        :rtype: list</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">predict_res</span> <span class="o">=</span> <span class="n">ut</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">probabilities</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
     
        <span class="k">return</span> <span class="n">predict_res</span> </div>
        
<div class="viewcode-block" id="ModelSelection.predict_proba"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.predict_proba">[docs]</a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predcit probabilities for a given model</span>
<span class="sd">        </span>
<span class="sd">        :param model: Model to predict a given value</span>
<span class="sd">        :type model: object</span>
<span class="sd">        :return: predicted values</span>
<span class="sd">        :rtype: array</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_X_test</span><span class="p">())[:,</span><span class="mi">1</span><span class="p">]</span></div>
 

<div class="viewcode-block" id="ModelSelection.confusion_matrix"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.confusion_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute confusion matrix to evaluate the accuracy of a classification.</span>
<span class="sd">        By definition, a confusion matrix C is such that Cij is equal to the number</span>
<span class="sd">        of observations known to be in group i and predicted to be in group j.</span>
<span class="sd">        </span>
<span class="sd">        For more information, see scikit learn documentation:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html</span>
<span class="sd">            </span>
<span class="sd">        :param Y_pred: Estimated targets as returned by a classifier.</span>
<span class="sd">        :type Y_pred: array of shape n_samples</span>
<span class="sd">        :param labels: List of labels to index the matrix. Defaults to None.</span>
<span class="sd">        :type labels: array of shape n_classes or None</span>
<span class="sd">        :param sample_weight: Sample weights. Defaults to None.</span>
<span class="sd">        :type sample_weight: array of shape n_samples or None</span>

<span class="sd">        :return: Confusion matrix whose i-th row and j-th column entry indicates </span>
<span class="sd">            the number of samples with true label being i-th class and </span>
<span class="sd">            predicted label being j-th class.</span>
<span class="sd">        :rtype: ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="k">return</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_Y_test</span><span class="p">(),</span> <span class="n">Y_pred</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">))</span></div>
    
           
<div class="viewcode-block" id="ModelSelection.calc_auc"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.calc_auc">[docs]</a>    <span class="k">def</span> <span class="nf">calc_auc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">curve</span> <span class="o">=</span> <span class="s2">&quot;roc&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;AUC stands for &quot;Area under the ROC Curve&quot;. That is, AUC measures the entire</span>
<span class="sd">        two-dimensional area underneath the entire ROC curve from (0,0) to (1,1)</span>
<span class="sd">        The Precission-Recall AUC is just like the ROC AUC. in that it summarizes the curve with a range</span>
<span class="sd">        of threshold values as a single score.</span>
<span class="sd">        </span>
<span class="sd">        :param predictions: Target scores, can either be probability estimates </span>
<span class="sd">            of the positive class, or non-thresholded measure of decisions.</span>
<span class="sd">        :type predictions: ndarray of shape n_samples</span>
<span class="sd">        :param curve: If &#39;roc&#39;, computes Receiver Operatic Characteristic (ROC) curve,</span>
<span class="sd">            if &#39;precision-recall&#39;, computes Precision-Recall curve.</span>
<span class="sd">        :type curve: str</span>

<span class="sd">        :return: Returns the Area Under the Curve (AUC)</span>
<span class="sd">        :rtype: float</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/#:~:text=The%20Precision%2DRecall%20AUC%20is,a%20model%20with%20perfect%20skill.</span>
        <span class="n">auc_score</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">curve</span> <span class="o">==</span> <span class="s2">&quot;roc&quot;</span><span class="p">:</span>
        
            <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_Y_test</span><span class="p">(),</span> <span class="n">predictions</span><span class="p">)</span>
            <span class="n">auc_score</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>  
            
        <span class="k">elif</span> <span class="n">curve</span> <span class="o">==</span> <span class="s2">&quot;precision-recall&quot;</span><span class="p">:</span>
            
            <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_Y_test</span><span class="p">(),</span> <span class="n">predictions</span><span class="p">)</span>
            <span class="n">auc_score</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>    
            
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Invalid state of curve passed.&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">auc_score</span> </div>


<div class="viewcode-block" id="ModelSelection.cross_validation"><a class="viewcode-back" href="../../src.html#src.model.ModelSelection.cross_validation">[docs]</a>    <span class="k">def</span> <span class="nf">cross_validation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">n_splits</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes K-fold Corss-Validation and evaluate the metric(s) by using</span>
<span class="sd">        StratifiedKFold and cross_validate from scikit-learn</span>
<span class="sd">        </span>
<span class="sd">        StratifiedKFold:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html</span>
<span class="sd">        cross_validate:</span>
<span class="sd">        https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html   </span>
<span class="sd">        </span>
<span class="sd">        :param model: Machine Learning algorithm to apply cross-validation.</span>
<span class="sd">        :type model: </span>
<span class="sd">        :param n_splits: Number of folds. Must be at least 2. Defaults to 10.</span>
<span class="sd">        :type n_splits: int</span>
<span class="sd">        :param n_jobs: Number of jobs to run in parallel. Training the estimator</span>
<span class="sd">            and computing the score are parallelized over the cross-validation splits.</span>
<span class="sd">            Defaults to None</span>
<span class="sd">        :type n_jobs: int</span>

<span class="sd">        :return: The function will return a dictionary containing the metrics &quot;accuracy&quot;,</span>
<span class="sd">            &quot;precision&quot;, &quot;recall&quot;, and &quot;f1&quot; for boith training and validation sets.</span>
<span class="sd">        :rtype: dict</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Indices obtained according to the number of partitions for the cross validation</span>
        <span class="c1"># https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">n_splits</span> <span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="s1">&#39;recall&#39;</span><span class="p">,</span> <span class="s1">&#39;f1&#39;</span><span class="p">]</span>
        
        <span class="n">results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>
                                 <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_source</span><span class="p">(),</span>
                                 <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target</span><span class="p">(),</span>
                                 <span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span><span class="p">,</span>
                                 <span class="n">scoring</span> <span class="o">=</span> <span class="n">scores</span><span class="p">,</span>
                                 <span class="n">return_train_score</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;Training Accuracy scores&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span>
                <span class="s2">&quot;Mean Training Accuracy&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span>
                
                <span class="s2">&quot;Training Precision scores&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_precision&#39;</span><span class="p">],</span>
                <span class="s2">&quot;Mean Training Precision&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_precision&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                
                <span class="s2">&quot;Training Recall scores&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_recall&#39;</span><span class="p">],</span>
                <span class="s2">&quot;Mean Training Recall&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_recall&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                
                <span class="s2">&quot;Training F1 scores&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_f1&#39;</span><span class="p">],</span>
                <span class="s2">&quot;Mean Training F1 Score&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_f1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                
                <span class="s2">&quot;Validation Accuracy scores&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;test_accuracy&#39;</span><span class="p">],</span>
                <span class="s2">&quot;Mean Validation Accuracy&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;test_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span>
                
                <span class="s2">&quot;Validation Precision scores&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;test_precision&#39;</span><span class="p">],</span>
                <span class="s2">&quot;Mean Validation Precision&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;test_precision&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                
                <span class="s2">&quot;Validation Recall scores&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;test_recall&#39;</span><span class="p">],</span>
                <span class="s2">&quot;Mean Validation Recall&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;test_recall&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                
                <span class="s2">&quot;Validation F1 scores&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;test_f1&#39;</span><span class="p">],</span>
                <span class="s2">&quot;Mean Validation F1 Score&quot;</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;test_f1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="p">}</span></div></div>
    

<div class="viewcode-block" id="Model"><a class="viewcode-back" href="../../src.html#src.model.Model">[docs]</a><span class="k">class</span> <span class="nc">Model</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;This is a conceptual class representation of a model that can be used</span>
<span class="sd">    with Machine Learning algorithms.</span>
<span class="sd">    </span>
<span class="sd">    :param name: Name of the model.</span>
<span class="sd">    :type name: str</span>
<span class="sd">    :param model: Model to work with.</span>
<span class="sd">    :type model: object</span>
<span class="sd">    &quot;&quot;&quot;</span>
        
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        
<div class="viewcode-block" id="Model.get_name"><a class="viewcode-back" href="../../src.html#src.model.Model.get_name">[docs]</a>    <span class="k">def</span> <span class="nf">get_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a string with the name of the model.</span>
<span class="sd">        </span>
<span class="sd">        :return: The name of the model.</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span></div>

<div class="viewcode-block" id="Model.get_model"><a class="viewcode-back" href="../../src.html#src.model.Model.get_model">[docs]</a>    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the model to work with.</span>
<span class="sd">        </span>
<span class="sd">        :return: The model to work with.</span>
<span class="sd">        :rtype: object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span></div>

        
<div class="viewcode-block" id="Model.set_name"><a class="viewcode-back" href="../../src.html#src.model.Model.set_name">[docs]</a>    <span class="k">def</span> <span class="nf">set_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the name of the model.</span>
<span class="sd">        </span>
<span class="sd">        :param name: The name of the model.</span>
<span class="sd">        :type name: str </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span></div>
        
<div class="viewcode-block" id="Model.set_model"><a class="viewcode-back" href="../../src.html#src.model.Model.set_model">[docs]</a>    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the model to work with.</span>
<span class="sd">        </span>
<span class="sd">        :param model: The model to work with.</span>
<span class="sd">        :type model: object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span></div>

<div class="viewcode-block" id="Model.fit"><a class="viewcode-back" href="../../src.html#src.model.Model.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit (train) the model.</span>
<span class="sd">       </span>
<span class="sd">        :param X_train: All independent variables used to train the model.</span>
<span class="sd">        :type X_train: DataFrame</span>
<span class="sd">        :param Y_train: The dependent variables wich need to be predicted by the model.</span>
<span class="sd">        :type Y_train: Series</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span></div>
              
<div class="viewcode-block" id="Model.predict"><a class="viewcode-back" href="../../src.html#src.model.Model.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Given an unlabeled observations X, returns the predicted labels Y.</span>
<span class="sd">       </span>
<span class="sd">        :param X_test: Remaining observations to test the accuracy of the model.</span>
<span class="sd">        :type X_test: DataFrame</span>
<span class="sd">        :return: Returns the predicted labels Y.</span>
<span class="sd">        :rtype: Series</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">())</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">values</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="Model.get_metrics"><a class="viewcode-back" href="../../src.html#src.model.Model.get_metrics">[docs]</a>    <span class="nd">@abstractmethod</span> 
    <span class="k">def</span> <span class="nf">get_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_true</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>    
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Must override get_metrics&quot;</span><span class="p">)</span></div></div>
    
            
<div class="viewcode-block" id="ScikitLearnModel"><a class="viewcode-back" href="../../src.html#src.model.ScikitLearnModel">[docs]</a><span class="k">class</span> <span class="nc">ScikitLearnModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is a conceptual class representation of a model that is provided by</span>
<span class="sd">    the Scikit-learn library.</span>

<span class="sd">    :param name: Name of the model.</span>
<span class="sd">    :type name: str</span>
<span class="sd">    :param model: Model to work with.</span>
<span class="sd">    :type model: object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Call the __init__ function of the father class</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

        
<div class="viewcode-block" id="ScikitLearnModel.hyperparameter_tuning"><a class="viewcode-back" href="../../src.html#src.model.ScikitLearnModel.hyperparameter_tuning">[docs]</a>    <span class="nd">@abstractmethod</span> 
    <span class="k">def</span> <span class="nf">hyperparameter_tuning</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Must override hyperparameter_tuning&quot;</span><span class="p">)</span></div>
    

<div class="viewcode-block" id="ScikitLearnModel.get_metrics"><a class="viewcode-back" href="../../src.html#src.model.ScikitLearnModel.get_metrics">[docs]</a>    <span class="k">def</span> <span class="nf">get_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_true</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span> 
        <span class="sd">&quot;&quot;&quot;Computes the metrics &quot;accuracy&quot;, &quot;precision&quot;, &quot;recall&quot;, &quot;specifity&quot; and &quot;f1&quot; </span>
<span class="sd">        for a specified model and returns a Dataframe with all the information.</span>
<span class="sd">       </span>
<span class="sd">        :param Y_true: Ground truth (correct) target values.</span>
<span class="sd">        :type Y_true: array</span>
<span class="sd">        :param Y_pred: Estimated targets as returned by a classifier.</span>
<span class="sd">        :type Y_pred: array</span>
<span class="sd">        :return: Returns a DataFrame with all the metrics.</span>
<span class="sd">        :rtype: DataFrame</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">cv_scores</span> <span class="o">=</span> <span class="p">[]</span>  

        <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y_true</span><span class="p">,</span><span class="n">Y_pred</span><span class="p">)</span>

        <span class="c1"># Precision indicates the proportion of positive indentifications that are actually correct</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">Y_true</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">)</span>
        
        <span class="c1"># Recall (Sensivity) indicates the proportion of actual positives that were identified correctly</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">Y_true</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">)</span>
        
        <span class="c1"># Specificity indicates the proportion of actual negatives, which got predicted as the negative</span>
        <span class="n">specificity</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>  
        
        <span class="c1"># F1-Score is the weighted average of Precision and Recall, taking both false positives and</span>
        <span class="c1"># false negatives into account</span>
        <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">Y_true</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">)</span>  
        
        <span class="c1"># Accuracy ratio of correctly  predicted observation to the total observations</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_true</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">)</span>
    
        <span class="n">cv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">get_name</span><span class="p">(),</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">specificity</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">])</span>    
        <span class="n">results_df</span> <span class="o">=</span> <span class="n">ut</span><span class="o">.</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;model_name&#39;</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="s1">&#39;recall&#39;</span><span class="p">,</span> <span class="s1">&#39;specificity&#39;</span><span class="p">,</span> <span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
        <span class="k">return</span> <span class="n">results_df</span></div></div>
     
        
<div class="viewcode-block" id="LogisticRegression"><a class="viewcode-back" href="../../src.html#src.model.LogisticRegression">[docs]</a><span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">ScikitLearnModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is a conceptual class that represents Logistic Regression algorithm</span>
<span class="sd">    from scikit-learn library.</span>

<span class="sd">    :param name: Name of the model.</span>
<span class="sd">    :type name: str</span>
<span class="sd">    :param penalty: Specify the norm of the penalty, where &#39;none&#39; means no penalty is added,</span>
<span class="sd">        &#39;l2&#39; uses Ridge regularization, &#39;l1&#39; uses Lasso regularization, and &#39;elasticnet&#39;</span>
<span class="sd">        means that both &#39;l1&#39; and &#39;l2&#39; penalty terms are added. Defaults to &#39;l2&#39;.</span>
<span class="sd">    :type penalty: &#39;l1&#39;,&#39;l2&#39;,&#39;elasticnet&#39;, &#39;none&#39;</span>
<span class="sd">    :param dual: Dual or primal formulation. Dual formulation is only implemented </span>
<span class="sd">        for l2 penalty with liblinear solver. Defauls to &#39;False&#39;.</span>
<span class="sd">    :type dual: bool</span>
<span class="sd">    :param tol: Tolerance for stopping criteria. Defaults to &#39;1e-4&#39;.</span>
<span class="sd">    :type tol: float</span>
<span class="sd">    :param C: Inverse of regularization strenght, must be a positive float. </span>
<span class="sd">        Smaller values specify stronger regularization. Defaults to &#39;1.0&#39;.</span>
<span class="sd">    :type C: float</span>
<span class="sd">    :param fit_intercept: Specifies if a constant (bias or intercept) should be added</span>
<span class="sd">        to the decision function. Defaults to &#39;True&#39;.</span>
<span class="sd">    :type fit_intercept: bool</span>
<span class="sd">    :param intercept_scaling: Useful only when the solver &#39;liblinear&#39; is used and</span>
<span class="sd">        &#39;fit_intercept&#39; True. In this case, x becomes [x, self.intercept_scaling].</span>
<span class="sd">        Defaults to &#39;1&#39;.</span>
<span class="sd">    :type intercept_scaling: float</span>
<span class="sd">    :param class_weight: Weights associated with classes in the form {class_label: weight}.</span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type class_weight: dict, &#39;balanced&#39;, or None</span>
<span class="sd">    :param random_state: Used when solver == &#39;sag&#39;, &#39;saga&#39; or &#39;liblinear&#39; to shuffle the data. </span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type random_state: int, RandomState instance, or None</span>
<span class="sd">    :param solver: Algorith to use in the optimization problem. Defaults to &#39;lbfgs&#39;.</span>
<span class="sd">    :type solver: {&#39;newton-cg&#39;, &#39;lbfgs&#39;, &#39;liblinear&#39;, &#39;sag&#39;, &#39;saga&#39;}</span>
<span class="sd">    :param max_iter: Maximum number of iterations taken for the solvers to converge.</span>
<span class="sd">        Defaults to &#39;100&#39;.</span>
<span class="sd">    :type max_iter: int</span>
<span class="sd">    :param multi_class: If the option chosen is &#39;ovr&#39;, then a binary problem is fit </span>
<span class="sd">        for each label. For &#39;multinomial&#39; the loss minimised is the multinomial loss fit</span>
<span class="sd">        across the entire probability distribution, even when the data is binary.</span>
<span class="sd">        Defaults to &#39;auto&#39;.</span>
<span class="sd">    :type multi_class: {&#39;auto&#39; , &#39;ovr&#39; , &#39;multinomial&#39;}</span>
<span class="sd">    :param verbose: For the liblinear and lbfgs solvers set verbose to any positive</span>
<span class="sd">        number for verbosity. Defaults to &#39;0&#39;.</span>
<span class="sd">    :type verbose: int</span>
<span class="sd">    :param warm_start: If &#39;True&#39;, reuse the solution of the previous call to fit</span>
<span class="sd">        as initialization, otherwise, just erase the previous solution. Defauls to &#39;False&#39;.</span>
<span class="sd">    :type warm_start: bool</span>
<span class="sd">    :param n_jobs: Number of CPU cores used when parallelizing over classes of multi_class=&#39;ovr&#39;.</span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type n_jobs: int</span>
<span class="sd">    :param l1_ratio: The Elastic-Net mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.</span>
<span class="sd">        Only used if penalty = &#39;elasticnetV. Defaults to None.</span>
<span class="sd">    :type l1_ratio: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">penalty</span> <span class="o">=</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">dual</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="o">-</span><span class="mi">4</span><span class="p">),</span>
                 <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">fit_intercept</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">intercept_scaling</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">solver</span> <span class="o">=</span> <span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">multi_class</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
                 <span class="n">n_jobs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">l1_ratio</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">skLogisticRegression</span><span class="p">(</span><span class="n">penalty</span> <span class="o">=</span> <span class="n">penalty</span><span class="p">,</span> <span class="n">dual</span> <span class="o">=</span> <span class="n">dual</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span><span class="p">,</span>
                 <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">,</span> <span class="n">fit_intercept</span> <span class="o">=</span> <span class="n">fit_intercept</span><span class="p">,</span> <span class="n">intercept_scaling</span> <span class="o">=</span> <span class="n">intercept_scaling</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="n">class_weight</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span>
                 <span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">multi_class</span> <span class="o">=</span> <span class="n">multi_class</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="n">warm_start</span><span class="p">,</span> 
                 <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span><span class="p">,</span> <span class="n">l1_ratio</span> <span class="o">=</span> <span class="n">l1_ratio</span><span class="p">))</span>
        
        
<div class="viewcode-block" id="LogisticRegression.hyperparameter_tuning"><a class="viewcode-back" href="../../src.html#src.model.LogisticRegression.hyperparameter_tuning">[docs]</a>    <span class="k">def</span> <span class="nf">hyperparameter_tuning</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">penalty</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dual</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">fit_intercept</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                              <span class="n">intercept_scaling</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                              <span class="n">solver</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">multi_class</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                              <span class="n">n_jobs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">l1_ratio</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes a hyperparameter tuning for Logist Regression. </span>
<span class="sd">            User can provides a list of values for a specified parameter to perform</span>
<span class="sd">            the GridSearchCV method from scikit-learn.</span>
<span class="sd">    </span>
<span class="sd">        :param X_train: All independent variables used to train the model.</span>
<span class="sd">        :type name: DataFrame</span>
<span class="sd">        :param Y_train: The dependent variables wich need to be predicted by the model.</span>
<span class="sd">        :type Y_train: Series</span>
<span class="sd">        :param penalty: Specify the norm of the penalty, where &#39;none&#39; means no penalty is added,</span>
<span class="sd">            &#39;l2&#39; uses Ridge regularization, &#39;l1&#39; uses Lasso regularization, and &#39;elasticnet&#39;</span>
<span class="sd">            means that both &#39;l1&#39; and &#39;l2&#39; penalty terms are added. Defaults to None.</span>
<span class="sd">        :type penalty: list, None</span>
<span class="sd">        :param dual: Dual or primal formulation. Dual formulation is only implemented </span>
<span class="sd">            for l2 penalty with liblinear solver. Defauls to None.</span>
<span class="sd">        :type dual: list, None</span>
<span class="sd">        :param tol: Tolerance for stopping criteria. Defaults to None.</span>
<span class="sd">        :type tol: list, None</span>
<span class="sd">        :param C: Inverse of regularization strenght, must be a positive float. </span>
<span class="sd">            Smaller values specify stronger regularization. Defaults to None.</span>
<span class="sd">        :type C: flist, None</span>
<span class="sd">        :param fit_intercept: Specifies if a constant (bias or intercept) should be added</span>
<span class="sd">            to the decision function. Defaults to None.</span>
<span class="sd">        :type fit_intercept: list, None</span>
<span class="sd">        :param intercept_scaling: Useful only when the solver &#39;liblinear&#39; is used and</span>
<span class="sd">            &#39;fit_intercept&#39; True. In this case, x becomes [x, self.intercept_scaling].</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type intercept_scaling: list, None</span>
<span class="sd">        :param class_weight: Weights associated with classes in the form {class_label: weight}.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type class_weight: list, None</span>
<span class="sd">        :param random_state: Used when solver == &#39;sag&#39;, &#39;saga&#39; or &#39;liblinear&#39; to shuffle the data. </span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type random_state: list, None</span>
<span class="sd">        :param solver: Algorith to use in the optimization problem. Defaults to None.</span>
<span class="sd">        :type solver: list, None</span>
<span class="sd">        :param max_iter: Maximum number of iterations taken for the solvers to converge.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type max_iter: list, None</span>
<span class="sd">        :param multi_class: If the option chosen is &#39;ovr&#39;, then a binary problem is fit </span>
<span class="sd">            for each label. For &#39;multinomial&#39; the loss minimised is the multinomial loss fit</span>
<span class="sd">            across the entire probability distribution, even when the data is binary.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type multi_class: list, None</span>
<span class="sd">        :param verbose: For the liblinear and lbfgs solvers set verbose to any positive</span>
<span class="sd">            number for verbosity.</span>
<span class="sd">        :type verbose: list, None</span>
<span class="sd">        :param warm_start: If &#39;True&#39;, reuse the solution of the previous call to fit</span>
<span class="sd">            as initialization, otherwise, just erase the previous solution. Defaults to None.</span>
<span class="sd">        :type warm_start: list, None</span>
<span class="sd">        :param n_jobs: Number of CPU cores used when parallelizing over classes of multi_class=&#39;ovr&#39;.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type n_jobs: list, None</span>
<span class="sd">        :param l1_ratio: The Elastic-Net mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.</span>
<span class="sd">            Only used if penalty = &#39;elasticnetV. Defaults to None.</span>
<span class="sd">        :type l1_ratio: list, None</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">model_lr</span> <span class="o">=</span> <span class="n">skLogisticRegression</span><span class="p">()</span>
        
        <span class="c1"># https://stackoverflow.com/questions/2912615/how-to-iterate-over-function-arguments</span>
        <span class="n">arguments</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">arguments</span><span class="p">[</span><span class="s1">&#39;X_train&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">arguments</span><span class="p">[</span><span class="s1">&#39;Y_train&#39;</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">arguments</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model_lr</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">)</span>
        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
        
        <span class="n">best_params</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span>
        
        <span class="c1"># https://stackoverflow.com/questions/21986194/how-to-pass-dictionary-items-as-function-arguments-in-python</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">skLogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">))</span></div></div>



<div class="viewcode-block" id="RandomForest"><a class="viewcode-back" href="../../src.html#src.model.RandomForest">[docs]</a><span class="k">class</span> <span class="nc">RandomForest</span><span class="p">(</span><span class="n">ScikitLearnModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is a conceptual class that represents Random Forest classifier algorithm</span>
<span class="sd">    from scikit-learn library.</span>

<span class="sd">    :param name: Name of the model.</span>
<span class="sd">    :type name: str</span>
<span class="sd">    :param n_estimators: Number of trees in the forest. Defaults to &#39;100&#39;.</span>
<span class="sd">    :type n_estimators: int</span>
<span class="sd">    :param criterion: Function to measure the quality of a split. Defaults to &#39;gini&#39;.</span>
<span class="sd">    :type criterion: {&#39;gini&#39;, &#39;entropy&#39;, &#39;log_loss&#39;}.</span>
<span class="sd">    :param max_depth: The maximum depth of the tree. If None, nodes are expanded</span>
<span class="sd">        until all leaves are pure or contains less than &#39;min_sample_split&#39; samples.</span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type max_depth: int, None</span>
<span class="sd">    :param min_samples_split: The minimum number of samples required to split an</span>
<span class="sd">        internal node. Defaults to &#39;2&#39;.</span>
<span class="sd">    :type min_samples_split: int or float</span>
<span class="sd">    :param min_samples_leaf: The minimum number of samples required to be at a leaf node.</span>
<span class="sd">        Defaults to &#39;1&#39;.</span>
<span class="sd">    :type min_samples_leaf: int or float</span>
<span class="sd">    :param min_weight_fraction_leaf: The minimum weighted fraction of the sum total</span>
<span class="sd">        of weights (of all the input samples) required to be at a leaf node.</span>
<span class="sd">        Defaults to &#39;0.0&#39;.</span>
<span class="sd">    :type min_weight_fraction_leaf: float</span>
<span class="sd">    :param max_features: The number of features to consider when looking for</span>
<span class="sd">        the best split. Defaults to &#39;sqrt&#39;.</span>
<span class="sd">    :type max_features:{&#39;sqrt&#39;, &#39;log2&#39;, None}, int or float</span>
<span class="sd">    :param max_leaf_nodes: Grow trees with &#39;max_leaf_nodes&#39; in best-first fashion.</span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type max_leaf_nodes: int, None</span>
<span class="sd">    :param min_impurity_decrease: A node will be split if this split induces a decrease</span>
<span class="sd">        of the impurity greater than or equal to this value. Defaults to &#39;0.0&#39;.</span>
<span class="sd">    :type min_impurity_decrease: float</span>
<span class="sd">    :param bootstrap: Whether bootstrap samples are used when building trees. </span>
<span class="sd">        If &#39;False&#39;, the whole dataset is used to build each tree. Defauls to &#39;True&#39;.</span>
<span class="sd">    :type bootstrap: bool</span>
<span class="sd">    :param oob_score: Wheter to use out-of-bag samples to estimate the generalization score.</span>
<span class="sd">        Only available if boostrap is &#39;True&#39;. Defaults to &#39;False&#39;.</span>
<span class="sd">    :type oob_score: bool</span>
<span class="sd">    :param n_jobs: Number of CPU cores used when parallelizing over classes of multi_class=&#39;ovr&#39;.</span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type n_jobs: int</span>
<span class="sd">    :param random_state: Used when solver == &#39;sag&#39;, &#39;saga&#39; or &#39;liblinear&#39; to shuffle the data. </span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type random_state: int, RandomState instance, or None</span>
<span class="sd">    :param verbose: For the liblinear and lbfgs solvers set verbose to any positive</span>
<span class="sd">        number for verbosity. Defaults to &#39;0&#39;.</span>
<span class="sd">    :type verbose: int</span>
<span class="sd">    :param warm_start: If &#39;True&#39;, reuse the solution of the previous call to fit</span>
<span class="sd">        as initialization, otherwise, just erase the previous solution. Defauls to &#39;False&#39;.</span>
<span class="sd">    :type warm_start: bool</span>
<span class="sd">    :param class_weight: Weights associated with classes in the form {class_label: weight}.</span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type class_weight: dict, &#39;balanced&#39;, &#39;balanced_subsample&#39;, or None</span>
<span class="sd">    :param ccp_alpha: Complexity parameter used for Minimal Cost-Complexity Pruning.</span>
<span class="sd">        Defaults to &#39;0.0&#39;.</span>
<span class="sd">    :type ccp_alpha: non-negative float</span>
<span class="sd">    :param max_samples: If boostrap is &#39;True&#39;, the number of samples to draw from X to </span>
<span class="sd">        train each base estimator. Defaults to None.</span>
<span class="sd">    :type max_samples: int, float, None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">criterion</span> <span class="o">=</span> <span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
               <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">min_weight_fraction_leaf</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">max_features</span> <span class="o">=</span> <span class="s1">&#39;sqrt&#39;</span><span class="p">,</span> <span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
               <span class="n">min_impurity_decrease</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">bootstrap</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">oob_score</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
               <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ccp_alpha</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">max_samples</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">skRandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span><span class="p">,</span> <span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span> <span class="n">min_samples_split</span> <span class="o">=</span> <span class="n">min_samples_split</span><span class="p">,</span>
               <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">,</span> <span class="n">min_weight_fraction_leaf</span> <span class="o">=</span> <span class="n">min_weight_fraction_leaf</span><span class="p">,</span> <span class="n">max_features</span> <span class="o">=</span> <span class="n">max_features</span><span class="p">,</span> <span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">max_leaf_nodes</span><span class="p">,</span> 
               <span class="n">min_impurity_decrease</span> <span class="o">=</span> <span class="n">min_impurity_decrease</span><span class="p">,</span> <span class="n">bootstrap</span> <span class="o">=</span> <span class="n">bootstrap</span><span class="p">,</span> <span class="n">oob_score</span> <span class="o">=</span> <span class="n">oob_score</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span><span class="p">,</span>
               <span class="n">warm_start</span> <span class="o">=</span> <span class="n">warm_start</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="n">class_weight</span><span class="p">,</span> <span class="n">ccp_alpha</span> <span class="o">=</span> <span class="n">ccp_alpha</span><span class="p">,</span> <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">))</span>
        
        
<div class="viewcode-block" id="RandomForest.hyperparameter_tuning"><a class="viewcode-back" href="../../src.html#src.model.RandomForest.hyperparameter_tuning">[docs]</a>    <span class="k">def</span> <span class="nf">hyperparameter_tuning</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">n_estimators</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">criterion</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">min_samples_split</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
               <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">min_weight_fraction_leaf</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_features</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
               <span class="n">min_impurity_decrease</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">bootstrap</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">oob_score</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
               <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ccp_alpha</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_samples</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes a hyperparameter tuning for Random Forest Classifier. </span>
<span class="sd">            User can provides a list of values for a specified parameter to perform</span>
<span class="sd">            the GridSearchCV method from scikit-learn.</span>
<span class="sd">    </span>
<span class="sd">        :param X_train: All independent variables used to train the model.</span>
<span class="sd">        :type name: DataFrame</span>
<span class="sd">        :param Y_train: The dependent variables wich need to be predicted by the model.</span>
<span class="sd">        :type Y_train: Series</span>
<span class="sd">        :param n_estimators: Number of trees in the forest. Defaults to None.</span>
<span class="sd">        :type n_estimators:  list, None</span>
<span class="sd">        :param criterion: Function to measure the quality of a split.  Defaults to None.</span>
<span class="sd">        :type criterion:  list, None</span>
<span class="sd">        :param max_depth: The maximum depth of the tree. If None, nodes are expanded</span>
<span class="sd">            until all leaves are pure or contains less than &#39;min_sample_split&#39; samples.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type max_depth:  list, None</span>
<span class="sd">        :param min_samples_split: The minimum number of samples required to split an</span>
<span class="sd">            internal node.  Defaults to None.</span>
<span class="sd">        :type min_samples_split:  list, None</span>
<span class="sd">        :param min_samples_leaf: The minimum number of samples required to be at a leaf node.</span>
<span class="sd">             Defaults to None.</span>
<span class="sd">        :type min_samples_leaf:  list, None</span>
<span class="sd">        :param min_weight_fraction_leaf: The minimum weighted fraction of the sum total</span>
<span class="sd">            of weights (of all the input samples) required to be at a leaf node.</span>
<span class="sd">             Defaults to None.</span>
<span class="sd">        :type min_weight_fraction_leaf:  list, None</span>
<span class="sd">        :param max_features: The number of features to consider when looking for</span>
<span class="sd">            the best split. Defaults to None..</span>
<span class="sd">        :type max_features: list, None</span>
<span class="sd">        :param max_leaf_nodes: Grow trees with &#39;max_leaf_nodes&#39; in best-first fashion.</span>
<span class="sd">             Defaults to None.</span>
<span class="sd">        :type max_leaf_nodes: list, None</span>
<span class="sd">        :param min_impurity_decrease: A node will be split if this split induces a decrease</span>
<span class="sd">            of the impurity greater than or equal to this value. Defaults to None.</span>
<span class="sd">        :type min_impurity_decrease: list, None</span>
<span class="sd">        :param bootstrap: Whether bootstrap samples are used when building trees. </span>
<span class="sd">            If &#39;False&#39;, the whole dataset is used to build each tree.  Defaults to None.</span>
<span class="sd">        :type bootstrap: list, None</span>
<span class="sd">        :param oob_score: Wheter to use out-of-bag samples to estimate the generalization score.</span>
<span class="sd">            Only available if boostrap is &#39;True&#39;. Defaults to None.</span>
<span class="sd">        :type oob_score: list, None</span>
<span class="sd">        :param n_jobs: Number of CPU cores used when parallelizing over classes of multi_class=&#39;ovr&#39;.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type n_jobs: list, None</span>
<span class="sd">        :param random_state: Controls both the randomness of the bootstrapping of </span>
<span class="sd">            the samples used when building trees and the sampling of the features </span>
<span class="sd">            to consider when looking for the best split at each node.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type random_state: list, None</span>
<span class="sd">        :param verbose: For the liblinear and lbfgs solvers set verbose to any positive</span>
<span class="sd">            number for verbosity.  Defaults to None.</span>
<span class="sd">        :type verbose: list, None</span>
<span class="sd">        :param warm_start: If &#39;True&#39;, reuse the solution of the previous call to fit</span>
<span class="sd">            as initialization, otherwise, just erase the previous solution.  Defaults to None.</span>
<span class="sd">        :type warm_start: list, None</span>
<span class="sd">        :param class_weight: Weights associated with classes in the form {class_label: weight}.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type class_weight: list, None</span>
<span class="sd">        :param ccp_alpha: Complexity parameter used for Minimal Cost-Complexity Pruning.</span>
<span class="sd">             Defaults to None.</span>
<span class="sd">        :type ccp_alpha: list, None</span>
<span class="sd">        :param max_samples: If boostrap is &#39;True&#39;, the number of samples to draw from X to </span>
<span class="sd">            train each base estimator. Defaults to None.</span>
<span class="sd">        :type max_samples: list, None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">model_rf</span> <span class="o">=</span> <span class="n">skRandomForestClassifier</span><span class="p">()</span>
        
        <span class="c1"># https://stackoverflow.com/questions/2912615/how-to-iterate-over-function-arguments</span>
        <span class="n">arguments</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">arguments</span><span class="p">[</span><span class="s1">&#39;X_train&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">arguments</span><span class="p">[</span><span class="s1">&#39;Y_train&#39;</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">arguments</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model_rf</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">)</span>
        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
        
        <span class="n">best_params</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span>
        
        <span class="c1"># https://stackoverflow.com/questions/21986194/how-to-pass-dictionary-items-as-function-arguments-in-python</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">skRandomForestClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">))</span></div></div>



<div class="viewcode-block" id="SupportVectorClassif"><a class="viewcode-back" href="../../src.html#src.model.SupportVectorClassif">[docs]</a><span class="k">class</span> <span class="nc">SupportVectorClassif</span><span class="p">(</span><span class="n">ScikitLearnModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is a conceptual class that represents Support Vector Machine algorithm</span>
<span class="sd">    from scikit-learn library.</span>

<span class="sd">    :param name: Name of the model.</span>
<span class="sd">    :type name: str</span>
<span class="sd">    :param C: Regularization parameter. The strenght of the regularization is </span>
<span class="sd">        inversely proportional to C. Defaults to &#39;1.0&#39;.</span>
<span class="sd">    :type C: float</span>
<span class="sd">    :param kernel: Specifies the kernel type to be used in the algorithm. </span>
<span class="sd">        Defaults to &#39;rbf&#39;</span>
<span class="sd">    :type kernel: {&#39;linear&#39;, &#39;poly&#39;, &#39;rbf&#39;, &#39;sigmoid&#39;, &#39;precomputed&#39;} or callable</span>
<span class="sd">    :param degree: Degree of the polynomial kernel function when kernel is &#39;poly&#39;.</span>
<span class="sd">        Defaults to &#39;3&#39;.</span>
<span class="sd">    :type degree: int</span>
<span class="sd">    :param gamma: Kernek coefficient fot &#39;rbf&#39;, &#39;poly&#39; and &#39;sigmoid&#39;.</span>
<span class="sd">        Defaults to &#39;scale&#39;.</span>
<span class="sd">    :type gamma: {&#39;scale&#39;, &#39;auto&#39;} or float</span>
<span class="sd">    :param coef0: Independent term in kernel function, when kernel is &#39;poly&#39; or</span>
<span class="sd">        &#39;sigmoid&#39;. Defaults to &#39;0.0&#39;.</span>
<span class="sd">    :type coef0: float</span>
<span class="sd">    :param shrinking: Whether to use the shrinking heuristic. Defaults to &#39;True&#39;.</span>
<span class="sd">    :type shrinking: bool</span>
<span class="sd">    :param probability: Wheter to enable probability estimates. Deafuls to &#39;False&#39;.</span>
<span class="sd">    :type probability: bool</span>
<span class="sd">    :param tol: Tolerance for stopping criteria. Defaults to &#39;1e-3&#39;.</span>
<span class="sd">    :type tol: float</span>
<span class="sd">    :param cache_size: Specify the size of the kernelk cache (in MB). Defaults to &#39;200&#39;.</span>
<span class="sd">    :type cache_size: float</span>
<span class="sd">    :param class_weight: Weights associated with classes in the form {class_label: weight}.</span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type class_weight: dict, &#39;balanced&#39;, or None</span>
<span class="sd">    :param verbose: For the liblinear and lbfgs solvers set verbose to any positive</span>
<span class="sd">            number for verbosity.  Defaults to None.</span>
<span class="sd">    :type verbose: bool</span>
<span class="sd">    :param max_iter: Hard limit on iterations within solver, or -1 for no limit.</span>
<span class="sd">        Defaults to -1.</span>
<span class="sd">    :type max_iter: int</span>
<span class="sd">    :param decision_function_shape: Wheter to return a one-vs-rest (&#39;ovr&#39;) or </span>
<span class="sd">        one-vs-one (&#39;ovo&#39;) decision function. Defaults to &#39;ovr&#39;.</span>
<span class="sd">    :type decision_function_shape: {&#39;ovo&#39;, &#39;ovr&#39;}</span>
<span class="sd">    :param break_ties: If &#39;True&#39;, &#39;decision_functoin_shape&#39; = &#39;ovr&#39; and number of</span>
<span class="sd">        classes &gt; 2, predict will break ties according to the confidence values</span>
<span class="sd">        of &#39;decision_function&#39;. Defaults to &#39;False&#39;.</span>
<span class="sd">    :type break_ties: bool</span>
<span class="sd">    :param random_state: Used when solver == &#39;sag&#39;, &#39;saga&#39; or &#39;liblinear&#39; to shuffle the data. </span>
<span class="sd">        Defaults to None.</span>
<span class="sd">    :type random_state: int, RandomState instance, or None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">kernel</span> <span class="o">=</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">coef0</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> 
               <span class="n">shrinking</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">probability</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">),</span> <span class="n">cache_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
               <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">decision_function_shape</span> <span class="o">=</span> <span class="s1">&#39;ovr&#39;</span><span class="p">,</span> <span class="n">break_ties</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">,</span> <span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">degree</span> <span class="o">=</span> <span class="n">degree</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">coef0</span> <span class="o">=</span> <span class="n">coef0</span><span class="p">,</span> 
               <span class="n">shrinking</span> <span class="o">=</span> <span class="n">shrinking</span><span class="p">,</span> <span class="n">probability</span> <span class="o">=</span> <span class="n">probability</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span><span class="p">,</span> <span class="n">cache_size</span> <span class="o">=</span> <span class="n">cache_size</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="n">class_weight</span><span class="p">,</span> 
               <span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">decision_function_shape</span> <span class="o">=</span> <span class="n">decision_function_shape</span><span class="p">,</span> <span class="n">break_ties</span> <span class="o">=</span> <span class="n">break_ties</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span><span class="p">))</span>
        

<div class="viewcode-block" id="SupportVectorClassif.hyperparameter_tuning"><a class="viewcode-back" href="../../src.html#src.model.SupportVectorClassif.hyperparameter_tuning">[docs]</a>    <span class="k">def</span> <span class="nf">hyperparameter_tuning</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">kernel</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">degree</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">coef0</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">shrinking</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                             <span class="n">probability</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">cache_size</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                             <span class="n">verbose</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">decision_function_shape</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">break_ties</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes a hyperparameter tuning for Random Forest Classifier. </span>
<span class="sd">            User can provides a list of values for a specified parameter to perform</span>
<span class="sd">            the GridSearchCV method from scikit-learn.</span>
<span class="sd">    </span>
<span class="sd">        :param X_train: All independent variables used to train the model.</span>
<span class="sd">        :type name: DataFrame</span>
<span class="sd">        :param Y_train: The dependent variables wich need to be predicted by the model.</span>
<span class="sd">        :type Y_train: Series</span>
<span class="sd">        :param C: Regularization parameter. The strenght of the regularization is </span>
<span class="sd">            inversely proportional to C.  Defaults to None.</span>
<span class="sd">        :type C: list, None</span>
<span class="sd">        :param kernel: Specifies the kernel type to be used in the algorithm. </span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type kernel: list, None</span>
<span class="sd">        :param degree: Degree of the polynomial kernel function when kernel is &#39;poly&#39;.</span>
<span class="sd">             Defaults to None.</span>
<span class="sd">        :type degree: list, None</span>
<span class="sd">        :param gamma: Kernek coefficient fot &#39;rbf&#39;, &#39;poly&#39; and &#39;sigmoid&#39;.</span>
<span class="sd">             Defaults to None.</span>
<span class="sd">        :type gamma: list, None</span>
<span class="sd">        :param coef0: Independent term in kernel function, when kernel is &#39;poly&#39; or</span>
<span class="sd">            &#39;sigmoid&#39;. Defaults to None.</span>
<span class="sd">        :type coef0: list, None</span>
<span class="sd">        :param shrinking: Whether to use the shrinking heuristic. Defaults to None.</span>
<span class="sd">        :type shrinking: list, None</span>
<span class="sd">        :param probability: Wheter to enable probability estimates.  Defaults to None.</span>
<span class="sd">        :type probability: list, None</span>
<span class="sd">        :param tol: Tolerance for stopping criteria.  Defaults to None.</span>
<span class="sd">        :type tol: list, None</span>
<span class="sd">        :param cache_size: Specify the size of the kernelk cache (in MB).  Defaults to None.</span>
<span class="sd">        :type cache_size: list, None</span>
<span class="sd">        :param class_weight: Weights associated with classes in the form {class_label: weight}.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type class_weight: list, None</span>
<span class="sd">        :param verbose:  For the liblinear and lbfgs solvers set verbose to any positive</span>
<span class="sd">                number for verbosity.  Defaults to None.</span>
<span class="sd">        :type verbose: list, None</span>
<span class="sd">        :param max_iter: Hard limit on iterations within solver, or -1 for no limit.</span>
<span class="sd">             Defaults to None.</span>
<span class="sd">        :type max_iter: list, None</span>
<span class="sd">        :param decision_function_shape: Wheter to return a one-vs-rest (&#39;ovr&#39;) or </span>
<span class="sd">            one-vs-one (&#39;ovo&#39;) decision function. Defaults to None.</span>
<span class="sd">        :type decision_function_shape: list, None</span>
<span class="sd">        :param break_ties: If &#39;True&#39;, &#39;decision_functoin_shape&#39; = &#39;ovr&#39; and number of</span>
<span class="sd">            classes &gt; 2, predict will break ties according to the confidence values</span>
<span class="sd">            of &#39;decision_function&#39;.  Defaults to None.</span>
<span class="sd">        :type break_ties: list, None</span>
<span class="sd">        :param random_state: Used when solver == &#39;sag&#39;, &#39;saga&#39; or &#39;liblinear&#39; to shuffle the data. </span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type random_state: list, None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">model_svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
        
        <span class="c1"># https://stackoverflow.com/questions/2912615/how-to-iterate-over-function-arguments</span>
        <span class="n">arguments</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">arguments</span><span class="p">[</span><span class="s1">&#39;X_train&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">arguments</span><span class="p">[</span><span class="s1">&#39;Y_train&#39;</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">arguments</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model_svc</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">)</span>
        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
        
        <span class="n">best_params</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span>
        
        <span class="c1"># https://stackoverflow.com/questions/21986194/how-to-pass-dictionary-items-as-function-arguments-in-python</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">))</span></div></div>



<div class="viewcode-block" id="NeuralNetwork"><a class="viewcode-back" href="../../src.html#src.model.NeuralNetwork">[docs]</a><span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="n">ScikitLearnModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is a conceptual class that represents Neural Network algorithm</span>
<span class="sd">    from scikit-learn library.</span>

<span class="sd">    :param name: Name of the model.</span>
<span class="sd">    :type name: str</span>
<span class="sd">    :param hidden_layer_sizes: The ith element represents the number of neurons in the</span>
<span class="sd">        ith hidden layer. Defaults to &#39;(100,)&#39;.</span>
<span class="sd">    :type hidden_layer_sizes: tuple, length = n_layers - 2</span>
<span class="sd">    :param activation: Activation function for the hidden layer. Defaults to &#39;relu&#39;.</span>
<span class="sd">    :type activation: {&#39;identity&#39;, &#39;logistic&#39;, &#39;tanh&#39;, &#39;relu&#39;}</span>
<span class="sd">    :param solver: The solver for weight optimization. Defaults to &#39;adam&#39;.</span>
<span class="sd">    :type solver: {&#39;lbfgs&#39;, &#39;sgd&#39;, &#39;adam&#39;}</span>
<span class="sd">    :param alpha: Strength of the L2 regularization term (which is divided by the sample</span>
<span class="sd">        size when added to the loss). Defaults to &#39;0.0001&#39;.</span>
<span class="sd">    :type alpha: float</span>
<span class="sd">    :param batch_size: Size of minibatches for stochastic optimizers. Defaults to &#39;auto&#39;.</span>
<span class="sd">    :type batch_size: int, str</span>
<span class="sd">    :param learning_rate: Learning rate schedule for weight purposes. Defaults to &#39;constant&#39;.</span>
<span class="sd">    :type learning_rate: {&#39;constant&#39;, &#39;invscaling&#39;, &#39;adaptive&#39;}</span>
<span class="sd">    :param learning_rate_init: The initial learning rate used. It controls the step-size</span>
<span class="sd">        in updating the weights. Only when solver is &#39;sgd&#39; or &#39;adam&#39;. Defaults to &#39;0.001&#39;.</span>
<span class="sd">    :type learning_rate_init: float</span>
<span class="sd">    :param power_t: The exponent for inverse scaling learning rate. It is used in updating</span>
<span class="sd">        effective learning rate when the &#39;learning_rate&#39; is &#39;invscaling&#39;. Only when solver </span>
<span class="sd">        is &#39;sgd&#39;. Defaults to &#39;0.5&#39;</span>
<span class="sd">    :type power_t: float</span>
<span class="sd">    :param max_iter: Maximum number of iterations. Defaults to &#39;200&#39;.</span>
<span class="sd">    :type max_iter: int</span>
<span class="sd">    :param shuffle: Whether to shuffle samples in each iteration. Only when solver is &#39;sgd&#39; </span>
<span class="sd">        or &#39;adam&#39;. Defaults to &#39;True&#39;.</span>
<span class="sd">    :type shuffle: bool</span>
<span class="sd">    :param random_state: Determines random number generation for weights and bias initialization,</span>
<span class="sd">        train-test split and batch sampling. Defaults to None.</span>
<span class="sd">    :type random_state: int, RandomInstance, None</span>
<span class="sd">    :param tol:Tolerance for stopping criteria. Defaults to &#39;1e-4&#39;.</span>
<span class="sd">    :type tol: float</span>
<span class="sd">    :param verbose: For the liblinear and lbfgs solvers set verbose to any positive</span>
<span class="sd">            number for verbosity.  Defaults to &#39;False&#39;.</span>
<span class="sd">    :type verbose: bool</span>
<span class="sd">    :param warm_start: If &#39;True&#39;, reuse the solution of the previous call to fit</span>
<span class="sd">        as initialization, otherwise, just erase the previous solution. Defauls to &#39;False&#39;.</span>
<span class="sd">    :type warm_start: bool</span>
<span class="sd">    :param momentum: Momentum for gradient descent update. Should be between 0 and 1. </span>
<span class="sd">        Defaults to &#39;0.9&#39;.</span>
<span class="sd">    :type momentum: float</span>
<span class="sd">    :param nesterovs_momentum: Wheter to use Nesterov&#39;s momentum. Only when solves is &#39;sgd&#39;</span>
<span class="sd">        and momentum &gt; 0. Defaults to &#39;True&#39;.</span>
<span class="sd">    :type nesterovs_momentum: bool</span>
<span class="sd">    :param early_stopping: Whether to use early stopping to terminate training when </span>
<span class="sd">        validation score is not improving. Defaults to &#39;False&#39;.</span>
<span class="sd">    :type early_stopping: bool</span>
<span class="sd">    :param validation_fraction: The proportion of training data to set aside as validation </span>
<span class="sd">        set fot early stopping. Must be between 0 and 1. Only if early stopping is &#39;True&#39;.</span>
<span class="sd">        Defaults to &#39;0.1&#39;.</span>
<span class="sd">    :type validation_fraction: float</span>
<span class="sd">    :param beta_1: Exponential decay rate for estimates of first moment vector in adam, </span>
<span class="sd">        should be between 0 and 1. Only used when solver is &#39;adam&#39;. Defaults to &#39;0.9&#39;.</span>
<span class="sd">    :type beta_1: float</span>
<span class="sd">    :param beta_2: Exponential decay rate for estimates of second moment vector in adam, </span>
<span class="sd">        should be between 0 and 1. Only used when solver is &#39;adam&#39;. Defaults to &#39;0.999&#39;.</span>
<span class="sd">    :type beta_2: float</span>
<span class="sd">    :param epsilon: Value for numerical stability in adam. Only used when solver is &#39;adam&#39;. </span>
<span class="sd">        Defaults to &#39;1e-8&#39;.</span>
<span class="sd">    :type epsilon: float</span>
<span class="sd">    :param n_iter_no_change: Maximum number of epoch to not meet tol improvement. </span>
<span class="sd">        Only when solver is &#39;sgd&#39; or &#39;adam&#39;. Defaults to &#39;10&#39;.</span>
<span class="sd">    :type n_iter_no_change: int</span>
<span class="sd">    :param max_fun: Maximum number of loss functions calls. Only when solver is &#39;lbfgs&#39;. </span>
<span class="sd">        Defaults to &#39;15000&#39;.</span>
<span class="sd">    :type max_fun: int</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,),</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">solver</span> <span class="o">=</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span>
               <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">learning_rate_init</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">power_t</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
               <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="o">-</span><span class="mi">4</span><span class="p">),</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
               <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterovs_momentum</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">early_stopping</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">validation_fraction</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> 
               <span class="n">beta_2</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span>  <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="o">-</span><span class="mi">8</span><span class="p">),</span> <span class="n">n_iter_no_change</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="o">-</span><span class="mi">8</span><span class="p">),</span> <span class="n">max_fun</span> <span class="o">=</span> <span class="mi">15000</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">skMLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="n">hidden_layer_sizes</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="p">,</span> <span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span><span class="p">,</span>
               <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">learning_rate_init</span> <span class="o">=</span> <span class="n">learning_rate_init</span><span class="p">,</span> <span class="n">power_t</span> <span class="o">=</span> <span class="n">power_t</span><span class="p">,</span>
               <span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="n">warm_start</span><span class="p">,</span>
               <span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">nesterovs_momentum</span> <span class="o">=</span> <span class="n">nesterovs_momentum</span><span class="p">,</span> <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">early_stopping</span><span class="p">,</span> <span class="n">validation_fraction</span> <span class="o">=</span> <span class="n">validation_fraction</span><span class="p">,</span> <span class="n">beta_1</span> <span class="o">=</span> <span class="n">beta_1</span><span class="p">,</span> 
               <span class="n">beta_2</span> <span class="o">=</span> <span class="n">beta_2</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">n_iter_no_change</span> <span class="o">=</span> <span class="n">n_iter_no_change</span><span class="p">,</span> <span class="n">max_fun</span> <span class="o">=</span> <span class="n">max_fun</span><span class="p">))</span>
        

<div class="viewcode-block" id="NeuralNetwork.hyperparameter_tuning"><a class="viewcode-back" href="../../src.html#src.model.NeuralNetwork.hyperparameter_tuning">[docs]</a>    <span class="k">def</span> <span class="nf">hyperparameter_tuning</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">solver</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> 
                                   <span class="n">learning_rate_init</span><span class="p">,</span> <span class="n">power_t</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> 
                                   <span class="n">warm_start</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">nesterovs_momentum</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="p">,</span>
                                   <span class="n">beta_1</span><span class="p">,</span> <span class="n">beta_2</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">n_iter_no_change</span><span class="p">,</span> <span class="n">max_fun</span><span class="p">):</span>
        
        <span class="sd">&quot;&quot;&quot;Computes a hyperparameter tuning for Random Forest Classifier. </span>
<span class="sd">            User can provides a list of values for a specified parameter to perform</span>
<span class="sd">            the GridSearchCV method from scikit-learn.</span>
<span class="sd">    </span>
<span class="sd">        :param X_train: All independent variables used to train the model.</span>
<span class="sd">        :type name: DataFrame</span>
<span class="sd">        :param Y_train: The dependent variables wich need to be predicted by the model.</span>
<span class="sd">        :type Y_train: Series</span>
<span class="sd">        :param hidden_layer_sizes: The ith element represents the number of neurons in the</span>
<span class="sd">            ith hidden layer. Defaults to None.</span>
<span class="sd">        :type hidden_layer_sizes:  list, None</span>
<span class="sd">        :param activation: Activation function for the hidden layer. Defaults to None.</span>
<span class="sd">        :type activation:  list, None</span>
<span class="sd">        :param solver: The solver for weight optimization. Defaults to None.</span>
<span class="sd">        :type solver:  list, None</span>
<span class="sd">        :param alpha: Strength of the L2 regularization term (which is divided by the sample</span>
<span class="sd">            size when added to the loss). Defaults to None.</span>
<span class="sd">        :type alpha:  list, None</span>
<span class="sd">        :param batch_size: Size of minibatches for stochastic optimizers. Defaults to None.</span>
<span class="sd">        :type batch_size:  list, None</span>
<span class="sd">        :param learning_rate: Learning rate schedule for weight purposes. Defaults to None.</span>
<span class="sd">        :type learning_rate: list, None</span>
<span class="sd">        :param learning_rate_init: The initial learning rate used. It controls the step-size</span>
<span class="sd">            in updating the weights. Only when solver is &#39;sgd&#39; or &#39;adam&#39;. Defaults to None.</span>
<span class="sd">        :type learning_rate_init:  list, None</span>
<span class="sd">        :param power_t: The exponent for inverse scaling learning rate. It is used in updating</span>
<span class="sd">            effective learning rate when the &#39;learning_rate&#39; is &#39;invscaling&#39;. Only when solver </span>
<span class="sd">            is &#39;sgd&#39;. Defaults to None.</span>
<span class="sd">        :type power_t:  list, None</span>
<span class="sd">        :param max_iter: Maximum number of iterations. Defaults to None.</span>
<span class="sd">        :type max_iter:  list, None</span>
<span class="sd">        :param shuffle: Whether to shuffle samples in each iteration. Only when solver is &#39;sgd&#39; </span>
<span class="sd">            or &#39;adam&#39;. Defaults to None.</span>
<span class="sd">        :type shuffle:  list, None</span>
<span class="sd">        :param random_state: Determines random number generation for weights and bias initialization,</span>
<span class="sd">            train-test split and batch sampling. Defaults to None.</span>
<span class="sd">        :type random_state:  list, None</span>
<span class="sd">        :param tol:Tolerance for stopping criteria. Defaults to None.</span>
<span class="sd">        :type tol:  list, None</span>
<span class="sd">        :param verbose: For the liblinear and lbfgs solvers set verbose to any positive</span>
<span class="sd">                number for verbosity.  Defaults to None.</span>
<span class="sd">        :type verbose: list, None</span>
<span class="sd">        :param warm_start: If &#39;True&#39;, reuse the solution of the previous call to fit</span>
<span class="sd">            as initialization, otherwise, just erase the previous solution. Defaults to None.</span>
<span class="sd">        :type warm_start:  list, None</span>
<span class="sd">        :param momentum: Momentum for gradient descent update. Should be between 0 and 1. </span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type momentum:  list, None</span>
<span class="sd">        :param nesterovs_momentum: Wheter to use Nesterov&#39;s momentum. Only when solves is &#39;sgd&#39;</span>
<span class="sd">            and momentum &gt; 0. Defaults to None.</span>
<span class="sd">        :type nesterovs_momentum:  list, None</span>
<span class="sd">        :param early_stopping: Whether to use early stopping to terminate training when </span>
<span class="sd">            validation score is not improving. Defaults to None.</span>
<span class="sd">        :type early_stopping: list, None</span>
<span class="sd">        :param validation_fraction: The proportion of training data to set aside as validation </span>
<span class="sd">            set fot early stopping. Must be between 0 and 1. Only if early stopping is &#39;True&#39;.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type validation_fraction: list, None</span>
<span class="sd">        :param beta_1: Exponential decay rate for estimates of first moment vector in adam, </span>
<span class="sd">            should be between 0 and 1. Only used when solver is &#39;adam&#39;. Defaults to None.</span>
<span class="sd">        :type beta_1: list, None</span>
<span class="sd">        :param beta_2: Exponential decay rate for estimates of second moment vector in adam, </span>
<span class="sd">            should be between 0 and 1. Only used when solver is &#39;adam&#39;. Defaults to None.</span>
<span class="sd">        :type beta_2: list, None</span>
<span class="sd">        :param epsilon: Value for numerical stability in adam. Only used when solver is &#39;adam&#39;. </span>
<span class="sd">           Defaults to None.</span>
<span class="sd">        :type epsilon: list, None</span>
<span class="sd">        :param n_iter_no_change: Maximum number of epoch to not meet tol improvement. </span>
<span class="sd">            Only when solver is &#39;sgd&#39; or &#39;adam&#39;. Defaults to None.</span>
<span class="sd">        :type n_iter_no_change: list, None</span>
<span class="sd">        :param max_fun: Maximum number of loss functions calls. Only when solver is &#39;lbfgs&#39;. </span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        :type max_fun: list, None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">model_mlp</span> <span class="o">=</span> <span class="n">skMLPClassifier</span><span class="p">()</span>
        
        <span class="c1"># https://stackoverflow.com/questions/2912615/how-to-iterate-over-function-arguments</span>
        <span class="n">arguments</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">arguments</span><span class="p">[</span><span class="s1">&#39;X_train&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">arguments</span><span class="p">[</span><span class="s1">&#39;Y_train&#39;</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">arguments</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model_mlp</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">)</span>
        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
        
        <span class="n">best_params</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span>
        
        <span class="c1"># https://stackoverflow.com/questions/21986194/how-to-pass-dictionary-items-as-function-arguments-in-python</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">skMLPClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">))</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Alba Casillas Rodr√≠guez.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

<style>
    .wy-nav-content-wrap {
        height: 100%;
        width: 100%;
        background: hsl(0, 0%, 100%);
        display: block;
    }

    .wy-nav-content {
        height: 100%;
        width: 100%;
        background: hsl(0, 0%, 100%);
    }

    .rst-content {
        width: 100%;
        height: 100%;
    }

    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search,
    .wy-nav-top {
        background: hsl(0, 2%, 10%);
    }

    /* Sidebar */
    .wy-nav-side {
        background: #85e4a5;
    }

    .caption {
        background: hsl(0, 0%, 100%);
    }

    .caption-text {
        color: hsl(0, 0%, 0%)
    }

    .wy-menu-vertical a {
        color: hsl(0, 0%, 0%)
    }

    .wy-menu-vertical a:hover {
        color: hsl(0, 0%, 100%)
    }
</style>


</body>
</html>